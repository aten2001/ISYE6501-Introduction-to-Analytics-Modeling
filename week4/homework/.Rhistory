df = [11.4,12.5,10.2,10.8,11.6]
df = vector[11.4,12.5,10.2,10.8,11.6]
df = vector(11.4,12.5,10.2,10.8,11.6)
df = (11.4,12.5,10.2,10.8,11.6)
df <-  c(11.4,12.5,10.2,10.8,11.6)
mean (df)
var (df)
rm(list=ls())
df <-  c(11.4,12.5,10.2,10.8,11.6)
mean (df)
var (df)
df <- vector(10.6,12.3,11.2,11.4,10.0)
df <- [10.6,12.3,11.2,11.4,10.0]
df <- c(10.6,12.3,11.2,11.4,10.0)
sd(df)
var(df)
root(0.75)
sqrt(0.75)
mean(df)
installed.packages()
installed.packages("tidyverse")
help("installed.packages")
install.packages("tidyverse")
install.packages("reshape")
updateR
install.packages("installr")
library(installr)
updateR()
updateR()
install.packages(c("caTools", "ggplot2", "kernlab", "kknn"))
tinytex:::is_tinytex()
291200 ^(1/8)
(1.15*0.92*1.2*0.9)^(1/4)
The results, represented in a matrix and in a graph show that the accuracy would be at its highest if k = 1, giving and accuracy of 72.4%(approx.)<br>
Therefore, using k = 1, I use the model again to test on the test data.<br>
```{r, echo = TRUE, message = FALSE, warning = FALSE}
set.seed(101)
knn_model4=kknn(R1~., train = train.data,test = test.data,k=1, scale = T)
sum(knn_model4$fitted.values == test.data$R1) / nrow(test.data)
```
The result is better what was expected, giving an accuracy of 81.8%(approx.)
tinytex::install_tinytex()
knitr::opts_chunk$set(echo = TRUE)
setwd("D:/ernie/self-study/GTxMicroMasters/Introduction to Analytics Modeling/week 1")
credit <- read.table("credit_card_data-headers.txt" , header = T)
head(credit)
library(kernlab)
library(kknn)
library(ggplot2)
library(dplyr)
library(caTools)
set.seed(101)
model.1 <- ksvm(x = as.matrix(credit[,1:10]),
y = as.factor(credit[,11]),
type = "C-svc" ,
scaled = TRUE ,
kernel = "vanilladot" ,
C = 100)
model.1
a <- colSums(model.1@xmatrix[[1]]*model.1@coef[[1]])
a0 <- model.1@b
pred1 <- predict(model.1,credit[,1:10])
res1 <- sum(pred1 == credit [,11]) / nrow(credit)
setwd("D:/ernie/self-study/GTxMicroMasters/Introduction to Analytics Modeling/week 1")
credit <- read.table("credit_card_data-headers.txt" , header = T)
head(credit)
library(kernlab)
library(kknn)
library(ggplot2)
library(dplyr)
library(caTools)
set.seed(101)
model.1 <- ksvm(x = as.matrix(credit[,1:10]),
y = as.factor(credit[,11]),
type = "C-svc" ,
scaled = TRUE ,
kernel = "vanilladot" ,
C = 100)
a <- colSums(model.1@xmatrix[[1]]*model.1@coef[[1]])
a0 <- model.1@b
model.1
a
a0
setwd("D:/ernie/self-study/GTxMicroMasters/Introduction to Analytics Modeling/week 1")
credit <- read.table("credit_card_data-headers.txt" , header = T)
head(credit)
library(kernlab)
library(kknn)
library(ggplot2)
library(dplyr)
library(caTools)
set.seed(101)
model.1 <- ksvm(x = as.matrix(credit[,1:10]),
y = as.factor(credit[,11]),
type = "C-svc" ,
scaled = TRUE ,
kernel = "vanilladot" ,
C = 100)
a <- colSums(model.1@xmatrix[[1]]*model.1@coef[[1]])
a0 <- model.1@b
pred1 <- predict(model.1,credit[,1:10])
res1 <- sum(pred1 == credit [,11]) / nrow(credit)
res1
#choosing best model : c =1 ~100
set.seed(101)
test.c <- list(1:100)
acc <- data.frame(matrix(ncol = 2, nrow = 100))
names(acc) <- c("c","accuracy")
for (i in test.c){
model <- ksvm(x = as.matrix(credit[,1:10]),
y = as.factor(credit[,11]),
type = "C-svc" ,
scaled = TRUE ,
kernel = "vanilladot" ,
C = i)
pred <- predict(model,credit[,1:10])
res.0 <- sum(pred1 == credit [,11]) / nrow(credit)
acc[i,1] <- i
acc[i,2] <- res.0
}
svm.plt <-ggplot(acc, aes(x = c , y = accuracy)) + geom_point() + geom_line(lty = "dotted" , color = "red")
svm.plt
#2.2.2
#Using other non-linear models
#Radial Basis kernel "Gaussian"
set.seed(101)
model.2 <- ksvm(x = as.matrix(credit[,1:10]),
y = as.factor(credit[,11]),
type = "C-svc" ,
scaled = TRUE ,
kernel = "rbfdot" ,
C = 100)
b <- colSums(model.2@xmatrix[[1]]*model.2@coef[[1]])
b0 <- model.1@b
pred2 <- predict(model.2,credit[,1:10])
res2 <- sum(pred2 == credit [,11]) / nrow(credit)
#Polynomial kernel
set.seed(101)
model.3 <- ksvm(x = as.matrix(credit[,1:10]),
y = as.factor(credit[,11]),
type = "C-svc" ,
scaled = TRUE ,
kernel = "polydot" ,
C = 100)
c <- colSums(model.3@xmatrix[[1]]*model.3@coef[[1]])
c0 <- model.3@b
pred3 <- predict(model.3,credit[,1:10])
res3 <- sum(pred3 == credit [,11]) / nrow(credit)
# Hyperbolic tangent kernel
set.seed(101)
model.4 <- ksvm(x = as.matrix(credit[,1:10]),
y = as.factor(credit[,11]),
type = "C-svc" ,
scaled = TRUE ,
kernel = "tanhdot" ,
C = 100)
d <- colSums(model.4@xmatrix[[1]]*model.4@coef[[1]])
d0 <- model.4@b
pred4 <- predict(model.4,credit[,1:10])
res4 <- sum(pred4 == credit [,11]) / nrow(credit)
#summaring up results
pred.list <- c(res1,res2,res3,res4)
kernel.list <- c("Linear","Radial Basis" ,"Polynomial" ,"Hyperbolic tangent")
result.df <- data.frame(kernel.list ,pred.list)
print(result.df)
R1 <-credit[,11]
pred5<- rep(0,(nrow(credit)))
set.seed(101)
for (i in 1:nrow(credit)){
#making sure that i won't use it self
knn.model=kknn(R1~., credit[-i,],credit[i,],k=1, scale = T)
pred5[i]<- as.integer(fitted(knn.model)+0.5)
}
res5 = sum(pred5 == R1) / nrow(credit)
res5
knn.df <- data.frame(matrix(nrow = 30, ncol = 2))
colnames(knn.df) <- c("k" , "accuracy")
set.seed(101)
for(n in 1:30){
for (i in 1:nrow(credit)){
knn_model=kknn(R1~., credit[-i,],credit[i,],k=n, scale = T)
pred5[i] <- as.integer(fitted(knn_model)+0.5)
res.00 <- sum(pred5 == R1) / nrow(credit)
knn.df[n,1]<- n
knn.df[n,2]<- res.00
}
}
knn.plt <-ggplot(knn.df, aes(x = k , y = accuracy)) + geom_point() + geom_line(lty = "dotted" , color = "red")
knn.plt
head(knn.df[order(-knn.df["accuracy"]),])
#3.1
#a
#k-fold Cross validation
acc2 <- data.frame(matrix(nrow = 30 ,ncol = 2))
names(acc2) <- c("k" , "accuracy")
set.seed(101)
for (i in 1:30){
knn_model2 <- cv.kknn(R1~ ., credit , kcv = 10 , k = i, scale = T)
pred6 <- round(knn_model2[[1]][,2])
res6 <- sum(pred6 == credit [,11]) / nrow(credit)
acc2[i,1] <- i
acc2[i,2] <- res6
}
head(acc2[order(-acc2["accuracy"]),])
knn.plt2 <-ggplot(acc2, aes(x = k , y = accuracy)) + geom_point() + geom_line(lty = "dotted" , color = "red")
knn.plt2
#best model
head(acc2[order(-acc2["accuracy"]),])
#splitting data
train.index <- sample(nrow(credit),nrow(credit) * 0.7)
train.data <-  credit[train.index,]
remaining_data <- credit[-train.index,]
vad.index <- sample(nrow(remaining_data),nrow(remaining_data) * 0.5)
vad.data <- remaining_data[vad.index,]
test.data <- remaining_data[-vad.index,]
#testing whether total rows are correct
nrow(test.data) + nrow(vad.data) + nrow(train.data) == nrow(credit)
set.seed(101)
acc3 <- data.frame(matrix(nrow = 30 ,ncol = 2))
names(acc3) <- c("k" , "accuracy")
pred7<- rep(0,(nrow(vad.data)))
for(n in 1:30){
knn_model3=kknn(R1~., train = train.data,test = vad.data,k=n, scale = T)
res7 <- sum(knn_model3$fitted.values == vad.data$R1) / nrow(vad.data)
acc3[n,1]<- n
acc3[n,2]<- res7
}
head(acc3[order(-acc3["accuracy"]),])
knn.plt3 <-ggplot(acc3, aes(x = k , y = accuracy)) + geom_point() + geom_line(lty = "dotted" , color = "red")
knn.plt3
tinytex::install_tinytex()
install.packages('tinytex')
install.packages("tinytex")
install.packages(c("backports", "haven", "tidyr"))
library(tinytex)
system("defaults write org.R-project.R force.LANG en_US.UTF-8")
Sys.setenv(LANG = "en")
127
+1
y+1
y+1
tinytex::install_tinytex()
if tinytex:::is_tinytex() is TRUE
if tinytex:::is_tinytex()
Sys.getlocale()
Sys.setlocale("LC_ALL","English")
install.packages("AER")
install.packages("stargrazer")
install.packages("stargrazer")
install.packages("lmtest")
library("AER")
library("stargazer")
install.packages("stargazer")
library("dyplr")
library("dplyr")
library(lmtest)
#load data set into workspace
#from package "AER"
data("CASchools")
rm(list = ls())
source('~/.active-rstudio-document', echo=TRUE)
class(CAschools)
class(CASchools)
#look at data set
head(CASchools)
view(CASchools)
CASchools
#SUmmary stat of STR and score
#select in dplyr package
CASchools %>%
select(STR,score)%>%
summary()
#create new variables using dplyr
#CASchools %>%
CASchools %>%
mutate( STR = students / teachers ) %>%
mutate( score = (read + math) / 2 ) -> CASchools
summary(CASchools)
#SUmmary stat of STR and score
#select in dplyr package
CASchools %>%
select(STR,score)%>%
summary()
source('~/.active-rstudio-document', echo=TRUE)
stargazer(CASchools , type = "text")
source('D:/ernie/waseda/2020春学期/Econometrics and Data Analysis using R/lecture code/regression 2.R', echo=TRUE)
#scatter plot
plot(score - STR,
data = CASchools,
main = "Scatterplot of TestScore and STR",
xlab = "STR (X)",
ylab = "Test Score (Y)")
source('D:/ernie/waseda/2020春学期/Econometrics and Data Analysis using R/lecture code/regression 2.R', echo=TRUE)
#scatter plot
plot(score ~ STR,
data = CASchools,
main = "Scatterplot of TestScore and STR",
xlab = "STR (X)",
ylab = "Test Score (Y)")
source('D:/ernie/waseda/2020春学期/Econometrics and Data Analysis using R/lecture code/regression 2.R', echo=TRUE)
source('D:/ernie/waseda/2020春学期/Econometrics and Data Analysis using R/lecture code/regression 2.R', echo=TRUE)
cor(CASchools$STR ,CASchools$score)
source('D:/ernie/waseda/2020春学期/Econometrics and Data Analysis using R/lecture code/regression 2.R', echo=TRUE)
source('D:/ernie/waseda/2020春学期/Econometrics and Data Analysis using R/lecture code/regression 2.R', echo=TRUE)
Sys.setenv(LANG = "en")
install.packages("randomForest")
library(randomForest)
#CART
crime_tree_fit <- train(
Crime ~ .,
data = crime,
method = 'rpart',
trControl = trainControl(method = 'boot_all', number = 10),
metric = 'RMSE'
)
library(caret)
install.packages("caret")
library(caret)
#CART
crime_tree_fit <- train(
Crime ~ .,
data = crime,
method = 'rpart',
trControl = trainControl(method = 'boot_all', number = 10),
metric = 'RMSE'
)
source('D:/ernie/self-study/GTxMicroMasters/Introduction to Analytics Modeling/week4/homework/week4homework.R', echo=TRUE)
rm(crime_tree_fit)
#CART
crime.tree <- train(
Crime ~ .,
data = crime,
method = 'rpart',
trControl = trainControl(method = 'boot_all', number = 10),
metric = 'RMSE'
)
summary(crime.tree)
crime.tree
prp(crime.tree)
crime.tree$finalModel
prp(crime.tree$finalModel)
source('D:/ernie/self-study/GTxMicroMasters/Introduction to Analytics Modeling/week4/homework/week4homework.R', echo=TRUE)
# tree <- rpart (Crime ~., method = "class" , data = crime)
# printcp(tree)
# summary(tree)
prp(tree)
tree$splits
summary(tree)
#CART
# set up train and testing split
train <- createDataPartition(crime_mod_df$Crime, p = .85, list = F)
#CART
# set up train and testing split
train <- createDataPartition(crime$Crime, p = .85, list = F)
# set up test and train datasets
crime.train <- crime[train,]
crime.test <- crime[-train,]
# check splits
dim(crime_train); dim(crime_test)
# check splits
dim(crime.train); dim(crime.test)
crime.tree <- train(
Crime ~ .,
data = crime.train,
method = 'rpart',
trControl = trainControl(method = 'boot_all', number = 10),
metric = 'RMSE'
)
crime.tree$finalModel
prp(crime.tree$finalModel)
source('D:/ernie/self-study/GTxMicroMasters/Introduction to Analytics Modeling/week4/homework/week4homework.R', echo=TRUE)
source('D:/ernie/self-study/GTxMicroMasters/Introduction to Analytics Modeling/week4/homework/week4homework.R', echo=TRUE)
#Random Forest
crime.forest <- train(
Crime ~ .,
data = crime.train,
method = 'rf',
trControl = trainControl(method = 'boot_all', number = 10),
metric = 'RMSE')
crime.forest$finalModel
prp(crime.forest$finalModel)
#Testing
crime.test %>%
add_predictions(., crime.tree) %>%
select('obs' = Crime, pred) %>%
#Testing
crime.test %>%
add_predictions(., crime.tree) %>%
select('obs' = Crime, pred)
install.packages("model.r")
install.packages("modelr")
install.packages("modelr")
install.packages("modelr")
library(modelr)
source('D:/ernie/self-study/GTxMicroMasters/Introduction to Analytics Modeling/week4/homework/week4homework.R', echo=TRUE)
#Testing
crime.res1 <- crime.test %>%
add_predictions(., crime.tree) %>%
select('observations' = Crime, pred) %>%
as.data.frame()
#Testing
crime.res1 <- crime.test %>%
add_predictions(., crime.tree) %>%
select('observations' = Crime, pred) %>%
as.data.frame()
crime.res2 <- crime.test %>%
add_predictions(., crime.forest) %>%
select('obs' = Crime, pred) %>%
as.data.frame()
crime.res2 <- crime.test %>%
add_predictions(., crime.forest) %>%
select('observations' = Crime, pred) %>%
as.data.frame()
crime.res1
crime.res2
postResample(obs = crime.res1$observations, pred = crime.res1$pred)
postResample(obs = crime.res2$observations, pred = crime.res2$pred)
#10.3
credit <- read.table("germancredit.txt" ,header = T) %>%
data.frame()
# fit model with cross validation - basic logistic regression
credit.logit <- train(
Class ~ .,
data = credit,
method = 'glm',
family = 'binomial',
trControl = trainControl(method = 'cv', classProbs = T),
metric = 'Accuracy')
head(credit)
View(credit)
#10.3
data("GermanCredit")
credit <- read.table(data("GermanCredit") ,header = T) %>%
data.frame()
#10.3
credit <-data("GermanCredit")
credit <- read.table(credit ,header = T) %>%
data.frame()
#10.3
credit <-data("GermanCredit")
credit <- read.table(credit ,header = T) %>%
data.frame()
credit <- read.table("germancredit.txt" ,header = T) %>%
data.frame()
head(credit)
View(credit)
#10.3
data("germancredit.txt")
#10.3
set.seed(101)
credit <- read.table("germancredit.txt" ,header = T)
head(credit)
View(credit)
View(credit)
#10.3
set.seed(101)
credit <- read.table("germancredit.txt" ,header = T)
credit <- read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data", header = FALSE)
View(credit)
str(credit)
credit <- read.table("germancredit.txt", header = FALSE)
str(credit)
# fit model with cross validation - basic logistic regression
credit.logit <- train(
V21 ~ .,
data = credit,
method = 'glm',
family = 'binomial',
trControl = trainControl(method = 'cv', classProbs = T),
metric = 'Accuracy')
credit$V21[credit$V21==1] <- 0
credit$V21[credit$V21==2] <- 1
# fit model with cross validation - basic logistic regression
credit.logit <- train(
V21 ~ .,
data = credit,
method = 'glm',
family = 'binomial',
trControl = trainControl(method = 'cv', classProbs = T),
metric = 'Accuracy')
credit.log <- glm(V21 ~ ., data = credit, family=binomial(link="logit"))
# Look at importance of predictors
summary(credit.log)
summary(credit.log)
creditPredict <- predict(credit.log, credit.log[,-21], type="response")
creditPredict <- predict(credit.log, credit[,-21], type="response")
table(credit.log$V21, round(creditPredict))
#Dividing data
credit.part <- createDataPartition(credit$V21, times = 1, p = 0.7, list=FALSE)
head(credit.part)
credit.train <- credit[creditPart,]
credit.train <- credit[credit.part,]
credit.valid <- credit[-credit.part,]
credit.log <- glm(V21 ~ ., data = credi.traint, family=binomial(link="logit"))
credit.log <- glm(V21 ~ ., data = credi.train, family=binomial(link="logit"))
credit.log <- glm(V21 ~ ., data = credit.train, family=binomial(link="logit"))
summary(credit.log)
creditPredict <- predict(credit.log, newdata=credit.valid[,-21], type="response")
table(credit.valid$V21, round(creditPredict))
Confusion.mat <- table(credit.valid$V21, round(creditPredict))
Sensitivity <- Confusion.mat[1,1]/sum(Confusion.mat[1,])
Sensitivity
Specfitity <-Confusion.mat[2,2]/sum(Confusion.mat[2,])
Specfitity
threshold <- 0.7
thres <- as.matrix(table(round(creditPredict > threshold), credit.valid$V21))
names(dimnames(thres)) <- c("Predicted", "Observed")
thres
Sensitivity2 <- thres[1,1]/sum(thres[1,])
Sensitivity2
Specfitity2 <-thres[2,2]/sum(thres[2,])
Specfitity2
